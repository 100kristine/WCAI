{
 "metadata": {
  "name": "",
  "signature": "sha256:b1add2635deb790b6ba49204f4081e657d0001b785d5cc7752be4297eaa63981"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import numpy as np\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "from gensim import corpora\n",
      "import gensim,re\n",
      "from collections import defaultdict,Counter\n",
      "from nltk.tokenize import regexp_tokenize\n",
      "import re"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 222
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%run 'reusableFunctions.ipynb'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 225
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Files\n",
      "d = \"line_item_purchase/\"\n",
      "f1 = \"line_1_KC_only.txt\"\n",
      "f2 = \"line_2_KC_only.txt\"\n",
      "f3 = \"test2.txt\"\n",
      "pdef = \"./data/product.txt\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def group_By_Household_Unanamed(df):\n",
      "    #Return dictionary of lines grouped by household ids, does not convert product names\n",
      "    ids = list(set(df['hh_id']))\n",
      "    dct = {}\n",
      "    for iden in ids:\n",
      "        dct[iden] = df[df['hh_id']==iden]['item_id'].values\n",
      "    return dct\n",
      "\n",
      "exclude = ['AMERIGAS.EMPTY.PROPANE.TANK.EXCHANGE',\n",
      " '40.LB.TOPSOIL',\n",
      " 'E/O.BONNIE.ECO.PREM.PEATVEG.HERB.5IN',\n",
      " '2X4-96\".PREMIUM.KD.WHITEWOOD.STUD',\n",
      " '5GAL.HOMER.BUCKET',\n",
      " '9.IN.PLASTIC.TRAY.LINER.-.WHITE',\n",
      " '1.CU.FT.MG.FLOWER.&.VEG.GARDEN.SOIL',\n",
      " 'PLASTIC.BAG.GOODS',\n",
      " 'E/O.VEGETABLE.PEAT.POT.RED.5IN',\n",
      " '30GAL.PAPER.LAWN.BAGS-5PK',\n",
      " '1/2\"X260\".PTFE.THRD.SEAL.TAPE',\n",
      " '66.KEY.KWIKSET',\n",
      " 'SCOTCH.BLUE.1.88\".PAINTERS.2090',\n",
      " '1.25.CU.FT.MIRACLE.GRO.POTTING.MIX',\n",
      " 'CHIP.2.0.FLAT.BRUSH',\n",
      " 'E/O.ECO.VEG.4.IN.PEAT.SHORT',\n",
      " '16OZ.GAPS.&.CRACKS.GREAT.STUFF',\n",
      " 'ENERGIZER.AA.36-PACK',\n",
      " 'BETTER.9.IN.TRAY.SET.-.8.PIECE',\n",
      " '2.CU.FT.SCOTTS.EARTHGRO.BRN.MULCH',\n",
      " '42GAL.3MIL.CONTRACTOR.TRASHBAG.32PK',\n",
      " 'ES.14W.DAYLIGHT.SPIRAL.BULB.4PK',\n",
      " '0.75.CU.FT.SCOTTS.PREMIUM.TOPSOIL',\n",
      " '2.CU.FT.CYPRESS.MULCH',\n",
      " 'SCRIPTO.AIM.N.FLAME..II.LIGHTER']\n",
      "\n",
      "#len(exclude) == 25"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Product Definitions\n",
      "Load product definitions (condense convenience and cards.rentals items)\n",
      "\n",
      "Alternate version of product definitions - use this if we want to get rid of the high frequency items. Uncomment to revert to original."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_product_def(pname):\n",
      "    #load conversions for product table\n",
      "    #Altered to group subcategories\n",
      "    dct = defaultdict()\n",
      "    \n",
      "    with open(pname) as f:\n",
      "        next(f)\n",
      "        for line in f:\n",
      "            line = line.split(\"|\")\n",
      "            #if line[5] == \"CONVENIENCE\":#Added to consolidate\n",
      "            #    pass\n",
      "                #dct[line[0]] = [\"CONVENIENCE\"]\n",
      "            #elif re.match(r\"\"\"[0-9\\-]+\"\"\",line[3]):\n",
      "            #    pass\n",
      "                #dct[line[0]] = [\"CARDS.RENTALS\"]\n",
      "            #else:\n",
      "                #print dct[line[0]]\n",
      "            dct[line[0]] = [\".\".join(line[1].split(\" \"))]\n",
      "    return dct\n",
      "\n",
      "\n",
      "\n",
      "pnames = load_product_def(pdef)\n",
      "print len(pnames.keys())\n",
      "print len(exclude)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "111916\n",
        "25\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Load Product Names, removing top 25 most common terms"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cleanDct(dct,exclude):\n",
      "    exclude = set(exclude) #exclude some of the most common\n",
      "    for key in dct.keys():\n",
      "        if dct[key][0] in exclude:\n",
      "            del dct[key]\n",
      "    return dct\n",
      "\n",
      "newPnames = cleanDct(pnames,exclude)\n",
      "print len(newPnames)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "111891\n"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Groups Purchases by Household ID\n",
      "get Date will include a tuple of (item name, date)."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def group_by_household(fname,d,pnames,getDate=False,convert=True):\n",
      "    all_households = defaultdict(list)\n",
      "    names = set(pnames.keys())\n",
      "    with open(d+fname) as f:\n",
      "        header = next(f).split('|')\n",
      "        hh_id,item_id,date = header.index('hh_id'),header.index('item_id'),header.index('trans_date')\n",
      "        for line in f:\n",
      "            line = line.split('|')\n",
      "            if convert:\n",
      "                if not getDate and (line[item_id] in names):                \n",
      "                    all_households[line[hh_id]] +=[pnames[line[item_id]][0].decode('latin-1').encode('utf-8')]\n",
      "                elif (line[item_id] in names):\n",
      "                    all_households[line[hh_id]] +=[(pnames[line[item_id]][0].decode('latin-1').encode('utf-8'),line[date])]\n",
      "                else:\n",
      "                    pass\n",
      "            else:\n",
      "                if not getDate and (line[item_id] in names):                \n",
      "                    all_households[line[hh_id]] +=[line[item_id].decode('latin-1').encode('utf-8')]\n",
      "                elif (line[item_id] in names):\n",
      "                    all_households[line[hh_id]] +=[([line[item_id].decode('latin-1').encode('utf-8')],line[date])]\n",
      "                else:\n",
      "                    pass\n",
      "    return all_households\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dct1 = group_by_household(f1,d,pnames,getDate=False)#newPnames,getDate=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Make Documents"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_documents(dct,concatDate=False):\n",
      "    keys = list(dct.keys())\n",
      "    print len(keys)\n",
      "    return [dct[key] for key in keys],keys"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "documents,household_keys = make_documents(dct1)\n",
      "documents[2]\n",
      "dictionary = corpora.Dictionary(documents)\n",
      "corpus = [dictionary.doc2bow(text) for text in documents]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'dct1' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-25-15fcd9955eb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhousehold_keys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdct1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mdictionary\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'dct1' is not defined"
       ]
      }
     ],
     "prompt_number": 25
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Run LDA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#lda = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=dictionary,num_topics=50,chunksize=1000,passes=50)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def runLDA(corpus,dictionary,numtopics,chunksize,passes,fname=\"\"):\n",
      "    lda = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=dictionary,num_topics=numtopics,chunksize=chunksize,passes=passes)\n",
      "    lda.save(\"LDA_\"+ str(numtopics) + \"_topics_\" + str(chunksize) + \"_chunks_\" + \"_\"+fname+\"_\" +str(passes) + \"_passes.txt\")\n",
      "    return lda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 34
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runLDA(corpus,dictionary,470,chunksize=2000,passes=10) #9:24 - 42"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "<gensim.models.ldamodel.LdaModel at 0x110d84c10>"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runLDA(corpus,dictionary,480,chunksize=2000,passes=10) #9:24 - 42"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "<gensim.models.ldamodel.LdaModel at 0x110d84b50>"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runLDA(corpus,dictionary,490,chunksize=2000,passes=10) #9:24 - 42"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 57,
       "text": [
        "<gensim.models.ldamodel.LdaModel at 0x10db6bbd0>"
       ]
      }
     ],
     "prompt_number": 57
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runLDA(corpus,dictionary,510,chunksize=2000,passes=10) 9:50"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 59,
       "text": [
        "<gensim.models.ldamodel.LdaModel at 0x10db6da50>"
       ]
      }
     ],
     "prompt_number": 59
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runLDA(corpus,dictionary,520,chunksize=2000,passes=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "<gensim.models.ldamodel.LdaModel at 0x10aa4e290>"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runLDA(corpus,dictionary,530,chunksize=2000,passes=10)\n",
      "print \"start: 1:25\"\n",
      "#finished - 7:20?"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "start: 1:25\n"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runLDA(corpus,dictionary,540,chunksize=2000,passes=20)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "<gensim.models.ldamodel.LdaModel at 0x10c923d10>"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runLDA(corpus,dictionary,500,chunksize=2000,passes=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 15,
       "text": [
        "<gensim.models.ldamodel.LdaModel at 0x110d84c90>"
       ]
      }
     ],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lda10 = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=dictionary,num_topics=10,chunksize=10000,passes=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "regexp_tokenize(topics[0],pattern='[0-9.*]+[a-s]')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getSentences(topic):\n",
      "    #Returns list of readable sentences\n",
      "    return [re.sub(\"[0-9*]+\",'',sentence).strip(\"\\\"'.\") for sentence in topic.split(\" + \")]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 159
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "re.match(r\"\"\"[0-9\\-]+\"\"\",\"017-001-004\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "<_sre.SRE_Match at 0x10fb74e68>"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 219
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Visualization"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dct2 =group_by_household(f1,d,pnames,getDate=True)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 201
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Per topic\n",
      "# Each data point belongs to a household\n",
      "# average distance between items by household\n",
      "# Fraction of sentences in that household\n",
      "\n",
      "def getSentenceFraction(topic,dct):\n",
      "    fractions,distances,households = [],[],[]\n",
      "    sentences = set(getSentences(topic))\n",
      "    for household in dct.keys():\n",
      "        intersect = set([item[0] for item in dct2[household]]) & sentences\n",
      "       \n",
      "        if len(intersect) != 0:\n",
      "            fractions.append(len(intersect)/len(sentences))\n",
      "            households.append(household)\n",
      "            distances.append(timeDistance(intersect,household,dct2))\n",
      "    return fractions,households,distances\n",
      "\n",
      "def parseDate(date):\n",
      "        return datetime.datetime.strptime(date,\"%d%b%Y\")\n",
      "\n",
      "def averageTimes(times):\n",
      "        averageTimes = []\n",
      "        i =0\n",
      "        if len(times)==1:\n",
      "            return 0\n",
      "        else:\n",
      "            while (i+1) < len(times):\n",
      "                averageTimes.append(times[i+1]-times[i])\n",
      "                i+=1\n",
      "        return sum([t.days for t in averageTimes])/len(averageTimes)\n",
      "    \n",
      "def timeDistance(intersect,householdID,dct):\n",
      "    #Get total time\n",
      "    times = [parseDate(item[1]) for item in dct[householdID] if item[0] in intersect]\n",
      "    times.sort()\n",
      "    return averageTimes(times)#(times[-1]-times[0]).days"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 263
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fractions,households,distances = getSentenceFraction(topics[0],dct2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 264
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def visualize_topic(topic,dct):\n",
      "    # For a particular topic, create charts to show the clustering of sentences\n",
      "    # time vs sentences\n",
      "    fractions,households,distances = getSentenceFraction(topic,dct)\n",
      "    plt.scatter(distances,fractions,alpha=0.5)\n",
      "    plt.ylabel(\"Fraction of items contained within topic\")\n",
      "    plt.xlabel(\"Average purchasing time between items\")\n",
      "    plt.show()\n",
      "    return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 268
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#Rolled up LDA"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "###Steps\n",
      "1. Group items in purchase table by household basket\n",
      "2. Exclude any product ids which have a many to 1 relationship with an OMS id [automatically done by rollup function]\n",
      "3. Roll up each item to its higher level category (try 1,2,3) \n",
      "4. Do LDA"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convertBaskets():\n",
      "    # For each basket in household baskets, remove all items which are product ids with multiple OMS ids \n",
      "    # Convert all items to their rolled up categories\n",
      "    pnames = load_product(pdef,consolidate=True,skip=False)\n",
      "    household_baskets = group_by_household(f1,d,pnames,getDate=False,convert=False)\n",
      "    exclude = set(IDs2Exclude())\n",
      "    rollup_convert = rollup()\n",
      "    rolledup_ids = set(rollup_convert.keys())\n",
      "    dct = defaultdict()\n",
      "    excluded,missing,total_items,added,consolidated = 0,0,0,0,0\n",
      "    for household in household_baskets.keys():\n",
      "        items = []\n",
      "        for item in household_baskets[household]:\n",
      "            if item not in exclude:\n",
      "                if item in rolledup_ids:\n",
      "                    items.append(rollup_convert[item])\n",
      "                    added += 1\n",
      "                else:\n",
      "                    missing += 1\n",
      "                    items.append(pnames[item][0].decode('latin-1').encode('utf-8'))\n",
      "                    if pnames[item][0]==\"CONVENIENCE\" or pnames[item][0]==\"CARDS.RENTALS\":\n",
      "                        consolidated +=1\n",
      "                total_items += 1\n",
      "            else:\n",
      "                excluded += 1\n",
      "        if len(items) > 0:\n",
      "            dct[household] = items\n",
      "    print \"Number of items in excluded category \",(excluded)\n",
      "    print \"Number of items missing from rolledup dct conversion \",(missing)\n",
      "    print \"Number of items in all baskets \",(total_items)\n",
      "    print \"Number of items added to documents \",(added)\n",
      "    print \"Number of items consolidated \",(consolidated)\n",
      "    return dct"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dct2 = convertBaskets()\n",
      "documents2,household_keys2 = make_documents(dct2)\n",
      "dictionary2 = corpora.Dictionary(documents2)\n",
      "corpus2 = [dictionary2.doc2bow(text) for text in documents2]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Number of items in excluded category  82\n",
        "Number of items missing from rolledup dct conversion  822354\n",
        "Number of items in all baskets  839563\n",
        "Number of items added to documents  17209\n",
        "Number of items consolidated  32325\n"
       ]
      },
      {
       "ename": "NameError",
       "evalue": "name 'make_documents' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-12-75b91cb3255a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdct2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvertBaskets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdocuments2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mhousehold_keys2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmake_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdct2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdictionary2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDictionary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcorpus2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdictionary2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocuments2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mNameError\u001b[0m: name 'make_documents' is not defined"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runLDA(corpus2,dictionary2,100,chunksize=2000,passes=10,fname=\"Rolled_up_misc_added\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 35,
       "text": [
        "<gensim.models.ldamodel.LdaModel at 0x11408b250>"
       ]
      }
     ],
     "prompt_number": 35
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runLDA(corpus2,dictionary2,200,chunksize=2000,passes=10,fname=\"Rolled_up_misc_added\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "<gensim.models.ldamodel.LdaModel at 0x114bb4d10>"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "runLDA(corpus2,dictionary2,500,chunksize=2000,passes=10,fname=\"Rolled_up_misc_added_consolidated\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "KeyboardInterrupt",
       "evalue": "",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-46-aaa7aa469930>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mrunLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Rolled_up_misc_added_consolidated\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;32m<ipython-input-34-b6a8cca88bea>\u001b[0m in \u001b[0;36mrunLDA\u001b[0;34m(corpus, dictionary, numtopics, chunksize, passes, fname)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mrunLDA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnumtopics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mid2word\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnumtopics\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mlda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LDA_\"\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumtopics\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_topics_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_chunks_\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\"_\"\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpasses\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_passes.txt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlda\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Tyche/anaconda/lib/python2.7/site-packages/gensim-0.10.1-py2.7.egg/gensim/models/ldamodel.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, eval_every, iterations, gamma_threshold)\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0;31m# if a training corpus was provided, start estimating the model right away\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 306\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Tyche/anaconda/lib/python2.7/site-packages/gensim-0.10.1-py2.7.egg/gensim/models/ldamodel.pyc\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, corpus, chunksize, decay, passes, update_every, eval_every, iterations, gamma_threshold)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0meval_every\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreallen\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk_no\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0meval_every\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumworkers\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 543\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_perplexity\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal_docs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlencorpus\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatcher\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;32m/Users/Tyche/anaconda/lib/python2.7/site-packages/gensim-0.10.1-py2.7.egg/gensim/models/ldamodel.pyc\u001b[0m in \u001b[0;36mlog_perplexity\u001b[0;34m(self, chunk, total_docs)\u001b[0m\n\u001b[1;32m    452\u001b[0m         \u001b[0mcorpus_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcnt\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdocument\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mchunk\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcnt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocument\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m         \u001b[0msubsample_ratio\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1.0\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtotal_docs\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 454\u001b[0;31m         \u001b[0mperwordbound\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbound\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubsample_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msubsample_ratio\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msubsample_ratio\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mcorpus_words\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    455\u001b[0m         logger.info(\"%.3f per-word bound, %.1f perplexity estimate based on a held-out corpus of %i documents with %i words\" %\n\u001b[1;32m    456\u001b[0m             (perwordbound, numpy.exp2(-perwordbound), len(chunk), corpus_words))\n",
        "\u001b[0;32m/Users/Tyche/anaconda/lib/python2.7/site-packages/gensim-0.10.1-py2.7.egg/gensim/models/ldamodel.pyc\u001b[0m in \u001b[0;36mbound\u001b[0;34m(self, corpus, gamma, subsample_ratio)\u001b[0m\n\u001b[1;32m    646\u001b[0m         \u001b[0;31m# E[log p(beta | eta) - log q (beta | lambda)]; assumes eta is a scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    647\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0m_lambda\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mElogbeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 648\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgammaln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_lambda\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgammaln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    649\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgammaln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meta\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_terms\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mgammaln\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_lambda\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    650\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "## Use checkfiles\n",
      "## Check for overlapping OMS ids in breadcrumb. (1 OMS ID has multiple descriptions)\n",
      "#344808 - same breadcrumb - single product ID with many OMS (same breadcrumb though, holiday mat didn't have the same breadcrumb)\n",
      "# Do more descriptive statistics (look in .check files to see how many breadcrumbs there are for any one product id)\n",
      "# Find some way to resolve this problem.\n",
      "\n",
      "\n",
      "#1. See how many breadcrumbs there are for any one product id (# breadcrumbs : 1 product id ratio) [Check the purchase frequency of these - if there are a lot of mappings but it\n",
      "# isn't seen in many purchases, we don't really care] (Histogram)\n",
      "#2. How many different breadcrumbs there are for 1 breadcrumb (344808) - saw blades - 1,2,3,4,5,6,7 (22 rows for duplicates) but all have the same breadcrumb (rollup?)\n",
      "\n",
      "# Concatenate categories: say Grout + Tiles & Tools (higher category) before doing LDA clustering!!!!\n",
      "# Email counts as soon as done.\n",
      "# Sequence mining"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 47
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "testF = open('./breadcrumb/breadcrumb.txt').read().split('\\n')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def clean(lines):\n",
      "    return [line.split('||')[0].split('\\t') + line.split('||')[1].split('\\t') for line in lines if len(line)>1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "line = testF[0].split('\\t')\n",
      "#line[3].split('||')[1]\n",
      "#line[3].split('||')[0].split('=')[1]\n",
      "line = line[:3] + [line[3].split('||')[1]] +  [line[3].split('||')[0].split('=')[1]] + line[4:]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadBreadCrumb():\n",
      "    #Load lines in breadcrumb file\n",
      "    lines = []\n",
      "    linecount = 0\n",
      "    with open('./breadcrumb/breadcrumb.txt') as f:\n",
      "        for line in f:\n",
      "            if len(line) > 1:\n",
      "                line = line.split('\\t')\n",
      "                line = line[:3] + line[3].split(\"||\") + line[4:]\n",
      "                lines.append(line)\n",
      "            else:\n",
      "                print line\n",
      "            linecount += 1\n",
      "    print linecount\n",
      "    return lines"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 146
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines = loadBreadCrumb()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "115790\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines = [line.split('\\t') for line in open('data/OMS_ITEM_ID.tsv').read().split('\\n')[1:]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def product_id_to_oms():\n",
      "    lines = [line.split('\\t') for line in open('data/OMS_ITEM_ID.tsv').read().split('\\n')[1:]]\n",
      "    dct = defaultdict(list)\n",
      "    for line in lines:\n",
      "        if len(line) > 1:\n",
      "            dct[line[0]] += [line[2].strip('\\r')]\n",
      "    for key in dct.keys(): # remove overlap\n",
      "        if len(dct[key]) > 1:\n",
      "            del dct[key]\n",
      "    return dct"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 136
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "exclude = IDs2Exclude()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "NameError",
       "evalue": "name 'IDs2Exclude' is not defined",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-139-ca80997a1a71>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mexclude\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mIDs2Exclude\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
        "\u001b[0;31mNameError\u001b[0m: name 'IDs2Exclude' is not defined"
       ]
      }
     ],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 219
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ids,mapping,breadcrumb_count = filterProducts()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "115790\n",
        "Total Lines: 115790"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Total Ids, no duplicates: 49784\n",
        "Total duplicated ids: 66006\n",
        "Duplicated ids, same breadcrumb: 20331\n",
        "Duplicated ids, removed: 45675\n"
       ]
      }
     ],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "keys = mapping.keys()\n",
      "keys.sort()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 226
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "mapping['344808']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 227,
       "text": [
        "'Specialty Drill Bits&Drill Bits'"
       ]
      }
     ],
     "prompt_number": 227
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "''"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines = loadBreadCrumb()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "115790\n"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "lines[0][4]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 168,
       "text": [
        "'Pneumatic Staplers'"
       ]
      }
     ],
     "prompt_number": 168
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(dct.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 138,
       "text": [
        "812465"
       ]
      }
     ],
     "prompt_number": 138
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dct[productIds[0]] = 1"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 114
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "dct.keys()\n",
      "del dct[dct.keys()[0]]\n",
      "dct.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "ename": "IndexError",
       "evalue": "list index out of range",
       "output_type": "pyerr",
       "traceback": [
        "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
        "\u001b[0;32m<ipython-input-124-a4ab36fb574c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mdel\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
        "\u001b[0;31mIndexError\u001b[0m: list index out of range"
       ]
      }
     ],
     "prompt_number": 124
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 220
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(keys)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 126,
       "text": [
        "115790"
       ]
      }
     ],
     "prompt_number": 126
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(set(keys))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 127,
       "text": [
        "49784"
       ]
      }
     ],
     "prompt_number": 127
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}