{
 "metadata": {
  "name": "",
  "signature": "sha256:f2dabf36ce768b9d2bef8ca15a244e619cba1fe9e7c593e9dd5857f7124cee61"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from __future__ import division\n",
      "import os, gensim, datetime\n",
      "from collections import defaultdict,Counter\n",
      "import matplotlib.pyplot as plt"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Folders"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "ldaModelsFolder = \"newldamodels/\"\n",
      "dataFolder = \"data\"\n",
      "chartsFolder = \"images\"\n",
      "\n",
      "d = \"line_item_purchase/\"\n",
      "f1 = \"line_1_KC_only.txt\"\n",
      "f2 = \"line_2_KC_only.txt\"\n",
      "f3 = \"test2.txt\"\n",
      "all_purchases = \"KC_only.txt\"\n",
      "pdef = \"data/product.txt\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Date and time processing"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def convertDate(date):\n",
      "    #convert only date\n",
      "    return datetime.datetime.strptime(date,\"%d%b%Y\")\n",
      "\n",
      "def convert(date):\n",
      "    #convert date and time\n",
      "    return datetime.datetime.strptime(date,\"%d%b%Y%H:%M:%S\")\n",
      "\n",
      "def convertTime(date):\n",
      "    #convert only time\n",
      "    return datetime.datetime.strptime(date,\"%H:%M:%S\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Market Basket Analysis"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getMarketBasketDct(d,f,byDate=True,noTime=False):\n",
      "    #Groups only by households\n",
      "    # byDate and noTime=False: returns {household:{date:[(item, time) for item in that market basket]}}\n",
      "    # byDate and noTime=True: returns {household:{date:[item for item in that market basket]}}\n",
      "    #else just {household:[items]}\n",
      "    \"\"\"\n",
      "    >>> marketBaskets = getMarketBasketDct(d,f1,byDate=True,noTime=False)\n",
      "    \"\"\"\n",
      "    if byDate:\n",
      "        dct = defaultdict(lambda : defaultdict(list))\n",
      "    else:\n",
      "        dct = defaultdict(list)\n",
      "    with open(d+f) as f:\n",
      "        header = next(f).split(\"|\")\n",
      "        hh_id,item = header.index('hh_id'),header.index('item_id'),\n",
      "        date,time = header.index('trans_date'),header.index('trans_time')\n",
      "        \n",
      "        for line in f:\n",
      "            line = line.split(\"|\")\n",
      "            if byDate:\n",
      "                if noTime:\n",
      "                    dct[line[hh_id]][line[date]]+=[line[item]] \n",
      "                else:\n",
      "                    dct[line[hh_id]][line[date]]+=[(line[item],line[time])] \n",
      "            else:\n",
      "                dct[line[hh_id]]+=[line[item]] \n",
      "    return dct"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Sliding Window"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getWindows(dct,hh_id):\n",
      "    #Returns baskets like: [['11MAR2012', '15MAR2012'], ['23MAR2012'],['22APR2012'],['29MAY2012']]\n",
      "    dates = [(convertDate(key),key) for key in dct[hh_id].keys()]\n",
      "    dates.sort()\n",
      "    if len(dates)==0:\n",
      "        return []\n",
      "    prev,windows,window = dates[0][0],[],[dates[0][1]]\n",
      "    for date in dates[1:]:\n",
      "        if (date[0] - prev).days <=7:\n",
      "            window.append(date[1]) \n",
      "        else:\n",
      "            windows.append(window)\n",
      "            window = [date[1]]\n",
      "        prev = date[0]\n",
      "    return windows\n",
      "\n",
      "def getBaskets(windows,dct,hh_id,pnames,BC=False):\n",
      "    #For each time in the window, create baskets of item ids\n",
      "    baskets = []\n",
      "    keys = set(pnames.keys())\n",
      "    for window in windows:\n",
      "        basket = []\n",
      "        for item in window:\n",
      "            if BC:\n",
      "                lst = [pnames[item] for item in dct[hh_id][item] if item in keys]\n",
      "            else:\n",
      "                lst = [pnames[item[0]][0] for item in dct[hh_id][item] if item in keys]\n",
      "            if len(lst) > 0:\n",
      "                basket += lst\n",
      "        if len(set(basket)) > 0: \n",
      "            baskets.append(set(basket))\n",
      "    return baskets\n",
      "\n",
      "def averageTimes(times):\n",
      "    averageTimes,i = [],0\n",
      "    if len(times)==1:\n",
      "        return 0\n",
      "    else:\n",
      "        while (i+1) < len(times):\n",
      "            averageTimes.append(times[i+1]-times[i])\n",
      "            i+=1\n",
      "    print [t.days/3600 for t in averageTimes]\n",
      "    return sum([t.days/3600 for t in averageTimes])/len(averageTimes)\n",
      "\n",
      "def timeDistance(baskets):\n",
      "    times = []\n",
      "    if len(baskets) == 1 or len(baskets) == 0:\n",
      "        return 0\n",
      "    else:\n",
      "        i = 0\n",
      "        while i+1 < len(baskets):\n",
      "            times.append(baskets[i+1] - baskets[i])\n",
      "            i+=1\n",
      "    return sum([t.days for t in times])/len(times)\n",
      "\n",
      "def getSentenceFraction(topic,dct,pnames):\n",
      "    #Households can now have multiple baskets, each basket is sorted by time\n",
      "    fractions,distances,households = [],[],[]\n",
      "    sentences = set(getSentences(topic))\n",
      "    keys = set(dct.keys())\n",
      "    for  household in dct.keys():\n",
      "        if household in keys:\n",
      "            baskets = getBaskets(getWindows(dct,household),dct,household,pnames)\n",
      "\n",
      "            for basket in dct[household].keys():\n",
      "                if len(basket) > 0:\n",
      "                    intersect = set(basket) & sentences\n",
      "                    if len(intersect) != 0:\n",
      "                        fractions.append(len(intersect))\n",
      "                        households.append(household)\n",
      "                        distances.append(time)\n",
      "    return fractions,set(households),distances"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Product Name Conversion"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def load_product(pdef,consolidate=False,skip=True):\n",
      "    #pnames\n",
      "    #load conversions for product table\n",
      "    #Altered to group subcategories\n",
      "    #if skip, will not save the consoldiated categories to the dictionary\n",
      "    dct = defaultdict()\n",
      "    with open(pdef) as f:\n",
      "        next(f)\n",
      "        for line in f:\n",
      "            line = line.split(\"|\")\n",
      "            if consolidate and line[5] == \"CONVENIENCE\":#Added to consolidate\n",
      "                if skip:\n",
      "                    pass\n",
      "                else:\n",
      "                    dct[line[0]] = [\"CONVENIENCE\"]\n",
      "            elif consolidate and re.match(r\"\"\"[0-9\\-]+\"\"\",line[3]):\n",
      "                if skip:\n",
      "                    pass\n",
      "                else:\n",
      "                    dct[line[0]] = [\"CARDS.RENTALS\"]\n",
      "            else:\n",
      "                dct[line[0]] = [\".\".join(line[1].split(\" \"))]\n",
      "    return dct\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Product"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def openProductsFile(name=\"data/product.txt\"):\n",
      "    #Open products file\n",
      "    return [line.split(\"|\") for line in open(name).read().split(\"\\n\")]\n",
      "\n",
      "def getLinesByTopic(lines,topic=\"FLOOR AND WALL TILE\",field=5):\n",
      "    #Get all lines \n",
      "    #TILE SET MATERIALS/TOOLS\n",
      "    return [line for line in lines if len(line)>field and line[field]==topic]\n",
      "\n",
      "def getFileInfo(fname):\n",
      "    #return topics, chunks, passes\n",
      "    l = fname.split('_')\n",
      "    return  int(l[1])#[int(i) for i in l[1],l[3],l[5]]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Loading TileSet Items"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadCategories():\n",
      "    #tileRelatedItems = categories.keys()\n",
      "    d = defaultdict()\n",
      "    with open('handlabeled_testset_kristinelabels.csv') as f:\n",
      "        for line in f:\n",
      "            line = line.split(',')\n",
      "            if line[2].strip(' ') != 'unclassified':\n",
      "                d[\".\".join(line[1].split(\" \")[1:-1])] = line[2].strip(' ') \n",
      "    lines = openProductsFile()\n",
      "    topics = getLinesByTopic(lines,topic=\"FLOOR AND WALL TILE\",field=5)\n",
      "    for line in topics:\n",
      "        d[\".\".join(line[1].split(\" \"))] = 'TILE' \n",
      "    return d\n",
      "\n",
      "allCategories = []\n",
      "\n",
      "def getFiles(dirname):\n",
      "    #Get all LDA files in directory\n",
      "    return [f for f in os.listdir(dirname[:-1]) if f[-10:] == 'passes.txt']\n",
      "\n",
      "def getAllCategories():\n",
      "    categories = loadCategories()\n",
      "    return list(set([categories[key] for key in categories.keys()]))\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Processing TileSet Data"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def categoryCount(cluster):\n",
      "    return cluster[0][0]\n",
      "\n",
      "def itemCount(cluster):\n",
      "    return cluster[1][0]\n",
      "\n",
      "def getCategories(cluster):\n",
      "    return cluster[0][1]\n",
      "\n",
      "def getItems(cluster):\n",
      "    return cluster[1][1]\n",
      "\n",
      "def getTileRelatedClusters(clusters):\n",
      "    \"\"\"Takes in lst of tuples \n",
      "    ( (categoryCount, set(Categories)),\n",
      "        (itemCount, set(items)))\"\"\"\n",
      "    numTileClusters = sum([1 if categoryCount(item)>3 else 0 for item in clusters])\n",
      "    tileRelatedClusters = clusters[:numTileClusters]\n",
      "    return numTileClusters,tileRelatedClusters"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 18
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Processing LDA Topics"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def cleanEntry(topic,excludeWeights=True):\n",
      "    if excludeWeights:\n",
      "        return [i.split('*')[1].strip('\\n') for i in topic.split(\" + \") if float(i.split('*')[0]) !=0.0]\n",
      "    return [(float(i.split('*')[0]),i.split('*')[1]) for i in topic.split(\" + \") if float(i.split('*')[0]) !=0.0]\n",
      "\n",
      "def cleanTopic(topic):\n",
      "    #Separate topics into readable lines \n",
      "    allItems = []\n",
      "    for sent in topic:\n",
      "        allItems += cleanEntry(sent)\n",
      "    return allItems\n",
      "\n",
      "def getSentences(topic,getWeights=False):\n",
      "    #Returns list of readable sentences\n",
      "    if not getWeights:\n",
      "        return cleanEntry(topic)\n",
      "    return cleanEntry(topic,excludeWeights=False)\n",
      "\n",
      "def getMatch(topic,pnames):\n",
      "    #find the number of in the intersection between topic and items\n",
      "    #Return as tuples (percentage,topic)\n",
      "    match = set(topic) & set(pnames.keys())\n",
      "    return len(match),match\n",
      "\n",
      "def countCategories(topic,pnames):\n",
      "    #Count main categories that the items fall into\n",
      "    match = [pnames[word] for word in topic if word in pnames.keys()]\n",
      "    #for word in topic:\n",
      "    #    if word in pnames.keys():\n",
      "    #        match += [pnames[word]]\n",
      "    return len(set(match)),set(match)\n",
      "\n",
      "def matchTopics(topics,pnames):\n",
      "    return [(countCategories(topic,pnames),getMatch(topic,pnames)) for topic in topics]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Visualization Tools"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def updateRowCol(row,col,count=4):\n",
      "    if col==(count-1):\n",
      "        row +=1\n",
      "        col = 0\n",
      "    else:\n",
      "        col += 1\n",
      "    return row,col  \n",
      "\n",
      "def makeCounter(lst):\n",
      "    c = Counter()\n",
      "    for item in lst:\n",
      "        c[item] += 1\n",
      "    return c\n",
      "\n",
      "def makeHistogram(counter,fname,title,ylabeln,keylimit=False,numPlots=1,color=\"Pastel1\"):\n",
      "    #Makes histogram from input counter. Put in fname to save to a file and title for label\n",
      "    labels = counter.keys()\n",
      "    if numPlots==1:\n",
      "        f, ax1 = plt.subplots(1, 1)\n",
      "    else:\n",
      "        f, axarr = plt.subplots(numPlots-1, 1)\n",
      "        f.set_figheight(30)\n",
      "        f.set_figwidth(15)\n",
      "        plt.tight_layout()\n",
      "        \n",
      "        plt.subplots_adjust(hspace = 1)\n",
      "        plt.subplots_adjust(wspace = .4)\n",
      "        \n",
      "    y = np.array([counter[label] for label in labels])\n",
      "    x = np.array([\" \".join(lab.split(\".\")) for lab in [labels][0]])\n",
      "    plt.ylabel(ylabeln)\n",
      "    f.suptitle(title,fontsize=20)\n",
      "    sns.set_context(rc={\"figure.figsize\": (20, 10)})\n",
      "    if numPlots==1:\n",
      "        sns.barplot(x,y,data=y,ax=ax1) \n",
      "        ax1.set_xticklabels(labels,rotation=90,fontsize=10)\n",
      "    else:\n",
      "        row,col = 0,0\n",
      "        if not keylimit:\n",
      "            items = counter.keys()\n",
      "        else:\n",
      "            items = keylimit\n",
      "        divisions = len(items)/numPlots\n",
      "        print numPlots,divisions,len(items)\n",
      "        for i in range(1,numPlots):\n",
      "            x = np.array(items[divisions*(i-1):divisions*i])\n",
      "            y = np.array([counter[item] for item in x])\n",
      "            sns.barplot(x,y,palette=color,data=y,ax=axarr[row]) \n",
      "            axarr[row].set_xticklabels(labels,rotation=90,fontsize=10)\n",
      "            row +=1\n",
      "    plt.savefig(fname)\n",
      "    \n",
      "    return\n",
      "\n",
      "def setColorPalette():\n",
      "    sns.set_context(\"talk\")\n",
      "    sns.set_palette(\"deep\", desat=.6)\n",
      "    sns.set_context(rc={\"figure.figsize\": (16, 8)})\n",
      "    sns.set_style(\"darkgrid\")\n",
      "    return"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##ID Rollup Check"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Rolling Up Categories"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def IDs2Exclude():\n",
      "    #Find product IDs which are mapped to multiple OMS ids\n",
      "    #linesOMS =  open('data/OMS_ITEM_ID.tsv').read().split('\\n')\n",
      "    #lines = [line.strip('\\r').split('\\t') for line in linesOMS[1:] if len(line)>1]\n",
      "    #overlap = defaultdict(list)\n",
      "    #for line in lines:\n",
      "    #    overlap[line[0]] += [line[1]]  \n",
      "    #return overlap\n",
      "    breadcrumb = loadBreadCrumb()\n",
      "    overlap = Counter()\n",
      "    for line in breadcrumb:\n",
      "        overlap[line[0]] += 1\n",
      "    return [key for key in overlap.keys() if overlap[key] >1]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 123
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def loadBreadCrumb():\n",
      "    #Load lines in breadcrumb file\n",
      "    lines = []\n",
      "    with open('./breadcrumb/breadcrumb.txt') as f:\n",
      "        for line in f:\n",
      "            if len(line) > 1:\n",
      "                line = line.split('\\t')\n",
      "                line = line[:3] + line[3].split(\"||\") + line[4:]\n",
      "                lines.append(line)\n",
      "    return lines\n",
      "\n",
      "def rollup(level=1):\n",
      "    #Create dictionary {Product ID: rolled up category}\n",
      "    level += 2\n",
      "    lines = loadBreadCrumb()\n",
      "    return {line[1]:line[level] for line in lines}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#Breadcrumb ids overlap with oms\n",
      "\"\"\"\n",
      "def product_id_to_oms():\n",
      "    #Convert product id to oms\n",
      "    #Does not contain any keys that have duplicate OMS ids\n",
      "    #ITEM_ID = ID in breadcrumb files, OMS_ID should correspond\n",
      "    # data/OMS_ITEM_ID.tsv:\n",
      "    #ITEM_ID\tITEM_DESC\tOMS_ITEM_ID\n",
      "    #3037718\t14 IN. X 19 IN. NORMANDIE CANVAS ART\t203283571\n",
      "    lines = [line.split('\\t') for line in open('data/OMS_ITEM_ID.tsv').read().split('\\n')[1:]]\n",
      "    dct = defaultdict(list)\n",
      "    dct2 = defaultdict(list)\n",
      "    for line in lines:\n",
      "        if len(line) > 1:\n",
      "            dct[line[0]] += [line[2].strip('\\r').strip('\\n')]\n",
      "            dct2[line[0]] += [line]\n",
      "    removed = []\n",
      "    for key in dct.keys(): # remove overlap\n",
      "        if len(dct[key]) > 1:\n",
      "            removed.append((key,dct[key]))\n",
      "            del dct[key]\n",
      "    f = open('data/removed_from_oms_conversion.txt','w')\n",
      "    f.writelines(\"ITEM_ID\\tOMS_IDS\" + '\\n')\n",
      "    for line in removed:\n",
      "        #,\";\".join(dct2[line[0]])\n",
      "        x = \";\".join([\"\\t\".join(i) for i in dct2[line[0]]])\n",
      "        \n",
      "        f.writelines(\"\\t\".join([line[0],\";\".join(line[1]),x])+\"\\n\")\n",
      "        f.writelines(\"\\n\")\n",
      "    f.close()\n",
      "    return dct\n",
      "\n",
      "x = product_id_to_oms()\n",
      "\"\"\"\n",
      "#Updated February 28, 2015\n",
      "def product_id_to_oms():\n",
      "    #Convert product id to oms\n",
      "    #Does not contain any keys that have duplicate OMS ids\n",
      "    #ITEM_ID = ID in breadcrumb files, OMS_ID should correspond\n",
      "    # data/OMS_ITEM_ID.tsv:\n",
      "    #ITEM_ID\tITEM_DESC\tOMS_ITEM_ID\n",
      "    #3037718\t14 IN. X 19 IN. NORMANDIE CANVAS ART\t203283571\n",
      "    \"\"\"\n",
      "    >>> x = product_id_to_oms()\n",
      "    { 287145 : ['100130438']\n",
      "    540639 : ['100621076', '202439738']\n",
      "    287140 : ['202563022']\n",
      "    #Product id: : [Breadcrumb/OMS ids]\n",
      "    \"\"\"\n",
      "    lines = [line.split('\\t') for line in open('data/OMS_ITEM_ID.tsv').read().split('\\n')[1:]]\n",
      "    dct = defaultdict(list)\n",
      "    dct2 = defaultdict(list)\n",
      "    for line in lines:\n",
      "        if len(line) > 1:\n",
      "            dct[line[0]] += [line[2].strip('\\r').strip('\\n')]\n",
      "            dct2[line[0]] += [line]\n",
      "    removed = []\n",
      "    for key in dct.keys(): # remove overlap\n",
      "        if len(dct[key]) > 1 and len(list(set(([item[1] for item in dct2[line[0]]])))) > 1:\n",
      "            removed.append((key,dct[key]))\n",
      "            del dct[key]\n",
      "    f = open('data/removed_from_oms_conversion_POSTFIX.txt','w')\n",
      "    f.writelines(\"ITEM_ID(Product)\\tOMS_IDS(Breadcrumb)\" + '\\n')\n",
      "    for line in removed:\n",
      "        #,\";\".join(dct2[line[0]])\n",
      "        x = \";\".join([\"\\t\".join(i) for i in dct2[line[0]]])\n",
      "        \n",
      "        f.writelines(\"\\t\".join([line[0],\";\".join(line[1]),x])+\"\\n\")\n",
      "        f.writelines(\"\\n\")\n",
      "    f.close()\n",
      "    return dct\n",
      "\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 66
    },
    {
     "cell_type": "code",
     "collapsed": true,
     "input": [
      "#Descriptive statistics for breadcrumb files\n",
      "def getId_Check(line):\n",
      "    return line[1]\n",
      "   \n",
      "def getBreadcrumb(line):\n",
      "    return line[4]\n",
      "\n",
      "def getHigherCat(line):\n",
      "    return line[5]\n",
      "\n",
      "def checkBreadcrumb(breadcrumb,ID,id_mapping):\n",
      "    return breadcrumb == id_mapping[ID]\n",
      "\n",
      "def filterProducts():\n",
      "    # \n",
      "    # id_mapping = {product id: breadcrumb}\n",
      "    # \n",
      "    f = open('data/removedBreadcrumbsFinalList.txt','w')\n",
      "    ids,id_mapping,filtered = set([]),defaultdict(),[]\n",
      "    lines = loadBreadCrumb() #unfiltered, loads all lines in breadcrumb file\n",
      "    breadcrumb_count = defaultdict(list)\n",
      "    duplicated_ids,duplicated_sameBreadcrumb = 0,0\n",
      "    for line in lines:\n",
      "        ID = line[1] #product id\n",
      "        breadcrumb = \"&\".join([getBreadcrumb(line),getHigherCat(line)]) \n",
      "        if ID in ids: #Id has been duplicated, but it is fine if the breadcrumb is the same\n",
      "            duplicated_ids += 1\n",
      "            if checkBreadcrumb(breadcrumb,ID,id_mapping):\n",
      "                filtered.append(line)\n",
      "                duplicated_sameBreadcrumb += 1\n",
      "            else:\n",
      "                f.writelines(\"\\t\".join(line)+\"\\n\")\n",
      "        else: #Add id to ids and mapping to breadcrumb. Save the line.\n",
      "            ids.add(ID)\n",
      "            id_mapping[ID] = breadcrumb\n",
      "            filtered.append(line)\n",
      "        breadcrumb_count[ID] += [line]\n",
      "    print \"Total Lines: %s\" % len(lines)\n",
      "    print \"Total Ids, no duplicates: %s\" % len(ids)\n",
      "    print \"Total duplicated ids: %s\" % duplicated_ids\n",
      "    print \"Duplicated ids, same breadcrumb: %s\" % duplicated_sameBreadcrumb\n",
      "    print \"Duplicated ids, removed: %s\" % (duplicated_ids - duplicated_sameBreadcrumb)\n",
      "    return filtered,id_mapping,breadcrumb_count\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 71
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Run LDA\n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def make_documents(dct,concatDate=False):\n",
      "    keys = list(dct.keys())\n",
      "    print len(keys)\n",
      "    return [dct[key] for key in keys],keys\n",
      "\n",
      "def runLDA(corpus,dictionary,numtopics,chunksize,passes,fname=\"\"):\n",
      "    lda = gensim.models.ldamodel.LdaModel(corpus=corpus,id2word=dictionary,num_topics=numtopics,chunksize=chunksize,passes=passes)\n",
      "    lda.save(\"LDA_\"+ str(numtopics) + \"_topics_\" + str(chunksize) + \"_chunks_\" + \"_\"+fname+\"_\" +str(passes) + \"_passes.txt\")\n",
      "    return lda"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "upOne = {'Artificial Christmas Trees',\n",
      " 'Bathroom Accessories',\n",
      " 'Bathroom Hardware',\n",
      " 'Cabinet Accessories',\n",
      " 'Carpet Tools & Accessories',\n",
      " 'Ceiling Fan Accessories',\n",
      " 'Ceramic Tile',\n",
      " 'Chain Link Fencing',\n",
      " 'Christmas Garland',\n",
      " 'Christmas Lights',\n",
      " 'Christmas Wreaths',\n",
      " 'Circuit Breakers',\n",
      " 'Clamps & Vices',\n",
      " 'Cleaners',\n",
      " 'Copper Pipe & Fittings',\n",
      " 'Decking',\n",
      " 'Decorative Wall Tiles',\n",
      " 'Door Locks & Deadbolts',\n",
      " 'Drills',\n",
      " 'Drip Irrigation Kits',\n",
      " 'Extension Cords',\n",
      " 'Fittings',\n",
      " 'Flashlights & Accessories',\n",
      " 'Framing Lumber & Studs',\n",
      " 'Garden Rakes',\n",
      " 'Gardening Tools',\n",
      " 'Glue Guns & Glue Sticks',\n",
      " 'Grinders',\n",
      " 'Hammers',\n",
      " 'Kitchen Sinks',\n",
      " 'Knives & Blades',\n",
      " 'Landscaping',\n",
      " 'Lawn Fertilizers',\n",
      " 'Lawn Sprinklers',\n",
      " 'Levels',\n",
      " 'Nails',\n",
      " 'PVC Pipe & Fittings',\n",
      " 'Paint Brushes',\n",
      " 'Paint Rollers',\n",
      " 'Paint Sprayers',\n",
      " 'Paper Products',\n",
      " 'Pedestal Sinks',\n",
      " 'Pliers',\n",
      " 'Plumbing Tools',\n",
      " 'Plywood',\n",
      " 'Ratchet & Socket Sets',\n",
      " 'Reconditioned Saws',\n",
      " 'Safety Equipment',\n",
      " 'Sanders',\n",
      " 'Saw Blades',\n",
      " 'Saws',\n",
      " 'Screwdrivers',\n",
      " 'Screws',\n",
      " 'Shears & Pruning Tools',\n",
      " 'Shower Heads & Hand Showers',\n",
      " 'Sink Faucets',\n",
      " 'Sump Pumps',\n",
      " 'Switch Plates',\n",
      " 'Thermostats',\n",
      " 'Toilet & Bidet Seats',\n",
      " 'Vacuums',\n",
      " 'Washers & Dryers',\n",
      " 'Weather Stripping',\n",
      " 'Wire',\n",
      " 'Wrenches'}\n",
      "\n",
      "upTwo = {'Bathroom Vanities',\n",
      " 'CPVC Pipe & Fittings',\n",
      " 'Drill Bits',\n",
      " 'Evaporative Coolers',\n",
      " 'Outdoor Power Equipment',\n",
      " 'Wall Plates',\n",
      " 'Windows',\n",
      " 'Wood Flooring'}"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 94
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "##Breadcrumb related products (change these to change rollup)"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "def breadcrumbsToKeep(breadcrumb_count):\n",
      "    \"\"\"Replaces oneBreadcrumb as the set of breadcrumbs that have been filtered and \n",
      "    do not have mismatched duplicates\"\"\"\n",
      "    def match(lst):\n",
      "        #check if the rolled up category is the same\n",
      "        return len(list(set([i[5] for i in lst]))) == 1\n",
      "    keep = []\n",
      "    noMatch,sameHigherLevel = 0,0\n",
      "    for bc in breadcrumb_count.keys(): \n",
      "        if len(breadcrumb_count[bc]) == 1:\n",
      "            keep.append(bc)\n",
      "        elif match(breadcrumb_count[bc]):\n",
      "            sameHigherLevel += 1\n",
      "            keep.append(bc)\n",
      "        else:\n",
      "            noMatch +=1\n",
      "    print \"No Match: unrelated breadcrumbs,\",noMatch,\"Rolled up Successfully,\",sameHigherLevel,\"total,\",len(breadcrumb_count)\n",
      "    return set(keep)\n",
      "\n",
      "rollupExtra = set(['Bare Tools', 'Bathroom Vanities & Cabinets', 'Paint', 'Electrical', 'Tile', 'Electrical Tools', 'Hard Wood Floors', 'Wall Plates', 'Hardware', 'Power Distribution', 'Lumber & Composites', 'Extension Cords & Surge Protectors', 'Safety & Security', 'Filters & Accessories', 'Vices & Fastening Tools', 'Pumps', 'Cleaning', 'Bathroom Sinks', 'Fasteners', 'Specialty Pipe & Fittings', 'Woodworking Tools', 'Hand Tools', 'Vacuum Cleaners & Floor Care', 'Pipes & Fittings', 'Christmas Trees', 'Bathroom Accessories & Hardware', 'Hand Tool Sets', 'Door Knobs & Hardware', 'Screwdrivers & Nut Drivers', 'Plumbing', 'Gardening Tools', 'Carpet & Carpet Tile', 'Building Materials', 'Drip Irrigation', 'Wall Plates & Jacks', 'Lawn Care', 'Christmas Wreaths & Garland', 'Power Tool Accessories', 'Energy Management', 'Watering & Irrigation', 'Measure & Layout Tools', 'Tub & Shower Faucets', 'Cleaning Supplies', 'Air Conditioners & Coolers', 'Toilet Seats & Bidets', 'Garden Tools', 'Kitchen', 'Power Tools'])\n",
      "nonSpecific = set(['Bathroom Accessories', 'Carpet Tools & Accessories', 'Bird Supplies', 'Outdoor Power Equipment', 'Garden Plants & Flowers', 'Workwear & Apparel', 'Plywood', 'Wood Flooring', 'Hammers', 'Surveillance Equipment', 'Christmas Garland', 'Decking', 'Christmas Lights', 'Landscaping', 'Pliers', 'Lawn Fertilizers', 'Pipes & Fittings', 'Windows', 'Saws', 'Sink Faucets', 'Ceiling Fan Accessories', 'Gardening Tools', 'Torches & Soldering Irons', 'Wall Decor', 'Chain Link Fencing', 'Christmas Wreaths', 'Screws'])\n",
      "\n",
      "def load_productBC(pdef,breadcrumb_count,hasBreadcrumb,goodBreadcrumbs): #same as pnames\n",
      "    def rollup(line):\n",
      "        #temporarily just rolling up to a high category\n",
      "        \"\"\"\n",
      "        lst = [i.strip(\"\\n\").strip(\" \").strip(\"\\r\") for i in line[4:8]]\n",
      "        if len(set(lst)&upOne) > 0:\n",
      "            return \"|\".join(lst[2:3])\n",
      "        elif len(set(lst)&upTwo) > 0:\n",
      "            return \"|\".join(lst[3:])\n",
      "        return \"|\".join(lst[:2])\n",
      "        \"\"\"\n",
      "        lst = [i.strip(\"\\n\").strip(\" \").strip(\"\\r\") for i in line[4:]]\n",
      "        if len(lst) >= 2:\n",
      "            return lst[1]\n",
      "        else:\n",
      "            return \"\"\n",
      "    pnames = defaultdict()\n",
      "    with open(pdef,'r') as f:\n",
      "        res = open(\"data/okBreadcrumbs.txt\",'w')\n",
      "        for line in f:\n",
      "            line = line.split('|')\n",
      "            if line[0] in hasBreadcrumb and line[0] in goodBreadcrumbs:\n",
      "                    #pnames[line[0]] = list(set(reduce(lambda x,y:x+y,[rollup(bc) for bc in breadcrumb_count[line[0]]])))\n",
      "                pnames[line[0]] = list(set([rollup(bc) for bc in breadcrumb_count[line[0]]]))[0]\n",
      "                res.writelines(\"\\t\".join([\"\\t\".join(bc) for bc in breadcrumb_count[line[0]]])+\"\\n\")\n",
      "                #else: Need to update this if needed\n",
      "                #    frequencies = [singleBCFreq[bc] for bc in breadcrumb_count[line[0]]]\n",
      "                #    pnames[line[0]] = breadcrumb_count[line[0]][frequencies.index(max(frequencies))]\n",
      "    return pnames\n",
      "#ids,mapping,breadcrumb_count = filterProducts()\n",
      "#hasBreadcrumb = set(breadcrumb_count.keys())\n",
      "#goodBreadcrumbs = breadcrumbsToKeep(breadcrumb_count) #Replaces one breadcrumb, now can 1 to many\n",
      "\n",
      "#x = load_productBC(pdef,breadcrumb_count,hasBreadcrumb,goodBreadcrumbs)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 116
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 103
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#pnames = load_productBC(pdef,singleBCFreq,breadcrumb_count,hasBreadcrumb)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\"\"\"def singleBreadcrumbFrequency(baskets,oneBreadcrumb,breadcrumb_count):\n",
      "    # {breadcrumb: total frequency in items in marketBaskets}\n",
      "    c = Counter()\n",
      "    for household in baskets.keys():\n",
      "        for item in baskets[household]:\n",
      "            if item in oneBreadcrumb:\n",
      "                c[breadcrumb_count[item][0]] +=1\n",
      "    return c\n",
      "hasBreadcrumb = set(breadcrumb_count.keys())\n",
      "oneBreadcrumb = set([key for key in breadcrumb_count.keys() if len(set(breadcrumb_count[key])) == 1]) #one to one product ids\n",
      "baskets = getMarketBasketDct(d,all_purchases,byDate=False,noTime=True) #{household:[items]}\n",
      "singleBCFreq = singleBreadcrumbFrequency(baskets,oneBreadcrumb,breadcrumb_count)\n",
      "\"\"\""
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 36,
       "text": [
        "'def singleBreadcrumbFrequency(baskets,oneBreadcrumb,breadcrumb_count):\\n    # {breadcrumb: total frequency in items in marketBaskets}\\n    c = Counter()\\n    for household in baskets.keys():\\n        for item in baskets[household]:\\n            if item in oneBreadcrumb:\\n                c[breadcrumb_count[item][0]] +=1\\n    return c\\nhasBreadcrumb = set(breadcrumb_count.keys())\\noneBreadcrumb = set([key for key in breadcrumb_count.keys() if len(set(breadcrumb_count[key])) == 1]) #one to one product ids\\nbaskets = getMarketBasketDct(d,all_purchases,byDate=False,noTime=True) #{household:[items]}\\nsingleBCFreq = singleBreadcrumbFrequency(baskets,oneBreadcrumb,breadcrumb_count)\\n'"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#%run './breadcrumb/descriptive_statistics_breadcrumb.ipynb'"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 35
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Topic Cleaning and Reading"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def getTopicCount(fname):\n",
      "    \"\"\">>>getTopicCount(\"LDA_530_topics_2000_chunks___10_passes.txt\")\n",
      "    530\n",
      "    \"\"\"\n",
      "    fname = fname.split(\"_\")\n",
      "    return int(fname[1])\n",
      "\n",
      "def loadLDA(fname,directory,words=40):\n",
      "    \"\"\">>> lda = loadLDA(\"LDA_50_topics_100_chunks_50_passes_SIMPLIFIED.txt\",resultsDir,100,words=40)\n",
      "    \"\"\"\n",
      "    #\"LDA_50_topics_100_chunks_50_passes_SIMPLIFIED.txt\"\n",
      "    lda = gensim.models.LdaModel.load(directory+fname)\n",
      "    numtopics = getTopicCount(fname)\n",
      "    return [getSentences(topic,getWeights=True) for topic in lda.show_topics(numtopics,num_words=words)]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}